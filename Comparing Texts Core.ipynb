{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0d0f6d-c77c-4da6-9fdd-f3da931132ea",
   "metadata": {},
   "source": [
    "# <u><center>Comparing Texts Core\n",
    "- Authored by: Eric N. Valdez\n",
    "- Date: 03/28/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397106bf-bdfd-4de9-82c2-0a82fe0d4fab",
   "metadata": {},
   "source": [
    "# <u>Comparing Texts:\n",
    "- In this assignment you will prepare and conduct EDA on a text dataset using SpaCy, NLTK, and WordCount\n",
    "- The dataet contains labeled real and fake news articles from around the 2017 US Presidential Elections. The dataser was originally from [Kaggle](https://www.kaggle.com/datasets/subhajournal/fake-and-real-news-data) and is licensed under the [GNU AFFERO GERNERLA PUBLIC LICENSE](https://www.gnu.org/licenses/agpl-3.0.html)\n",
    "  \n",
    "-  You can also download the data from [here](https://drive.google.com/file/d/16Dqjymk1tdZWPxexs7lM7z1RTk405PAL/view).\n",
    "  \n",
    "- If you haven't already, be sure to install SpaCy and download the English language model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e564b3-d76a-4d14-83d8-fb41e2cd68b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.10.13)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (66.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from spacy) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\valde\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "from spacy.cli import download\n",
    "download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72410750-9672-4e97-a744-aa5abfe747e8",
   "metadata": {},
   "source": [
    "# `Imports:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90494a7c-b8b2-401e-ba2f-2c763b22f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1ff0c-92ee-4aec-b5e4-89c6e6b3fc11",
   "metadata": {},
   "source": [
    "# `Custom Functions & Preprocessing:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc62554-727d-4a31-9d72-d0f834d3aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_preprocess_texts(\n",
    "    texts,\n",
    "    nlp=None,\n",
    "    remove_stopwords=True,\n",
    "    remove_punct=True,\n",
    "    use_lemmas=False,\n",
    "    disable=[\"ner\"],\n",
    "    batch_size=50,\n",
    "    n_process=-1,\n",
    "):\n",
    "    \"\"\"Efficiently preprocess a collection of texts using nlp.pipe()\n",
    "    Args:\n",
    "        texts (collection of strings): collection of texts to process (e.g. df['text'])\n",
    "        nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None; if None, it creates a default 'en_core_web_sm' pipe.\n",
    "        remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
    "        remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
    "        use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
    "        disable (list of strings, optional): named pipeline elements to disable. Defaults to [\"ner\"]: Used with nlp.pipe(disable=disable)\n",
    "        batch_size (int, optional): Number of texts to process in a batch. Defaults to 50.\n",
    "        n_process (int, optional): Number of CPU processors to use. Defaults to -1 (meaning all CPU cores).\n",
    "    Returns:\n",
    "        list of tokens\n",
    "    \"\"\"\n",
    "    # from tqdm.notebook import tqdm\n",
    "    from tqdm import tqdm\n",
    "    if nlp is None:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    processed_texts = []\n",
    "    for doc in tqdm(nlp.pipe(texts, disable=disable, batch_size=batch_size, n_process=n_process)):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_stopwords == True) and (token.is_stop == True):\n",
    "                # Continue the loop with the next token\n",
    "                continue\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_punct == True):\n",
    "                continue\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_space == True):\n",
    "                continue\n",
    "            \n",
    "            ## Determine final form of output list of tokens/lemmas\n",
    "            if use_lemmas:\n",
    "                tokens.append(token.lemma_.lower())\n",
    "            else:\n",
    "                tokens.append(token.text.lower())\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b63c4da-5d1f-442b-ae11-c5b8abf3585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_measures_finder(tokens, ngrams=2, measure='raw_freq', top_n=None, min_freq = 1,\n",
    "                             words_colname='Words'):\n",
    "    import nltk\n",
    "    if ngrams == 4:\n",
    "        MeasuresClass = nltk.collocations.QuadgramAssocMeasures\n",
    "        FinderClass = nltk.collocations.QuadgramCollocationFinder\n",
    "        \n",
    "    elif ngrams == 3: \n",
    "        MeasuresClass = nltk.collocations.TrigramAssocMeasures\n",
    "        FinderClass = nltk.collocations.TrigramCollocationFinder\n",
    "    else:\n",
    "        MeasuresClass = nltk.collocations.BigramAssocMeasures\n",
    "        FinderClass = nltk.collocations.BigramCollocationFinder\n",
    "\n",
    "    measures = MeasuresClass()\n",
    "    \n",
    "   \n",
    "    finder = FinderClass.from_words(tokens)\n",
    "    finder.apply_freq_filter(min_freq)\n",
    "    if measure=='pmi':\n",
    "        scored_ngrams = finder.score_ngrams(measures.pmi)\n",
    "    else:\n",
    "        measure='raw_freq'\n",
    "        scored_ngrams = finder.score_ngrams(measures.raw_freq)\n",
    "\n",
    "    df_ngrams = pd.DataFrame(scored_ngrams, columns=[words_colname, measure.replace(\"_\",' ').title()])\n",
    "    if top_n is not None:\n",
    "        return df_ngrams.head(top_n)\n",
    "    else:\n",
    "        return df_ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1f0b23-6446-4814-837b-afc93d494e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase column width\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55427f89-92e2-41a4-885e-1f427de69370",
   "metadata": {},
   "source": [
    "# `Load Data:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b0a01f2-24fa-44da-8739-a9d2071fd85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A whirlwind day in D.C. showcases Trump’s unorthodox views and shifting tone</td>\n",
       "      <td>Donald Trump endorsed an unabashedly noninterventionist approach to world affairs Monday during a day-long tour of Washington, casting doubt on the need for the North Atlantic Treaty Organization and expressing skepticism about a muscular U.S. mi...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In Baltimore's call for federal police probe, a new search for answers (+video)</td>\n",
       "      <td>While some Justice Department investigations are adversarial, a new model of collaborative reform is surprising police in some cities, as they find themselves included as part of the solution.\\n\\nSearching for a \"framework ... [to] heal,\" Baltimo...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump Proudly Declares: Most Of The People I’ve Insulted Deserved It</td>\n",
       "      <td>Trump Proudly Declares: Most Of The People I’ve Insulted Deserved It By Andrew Bradford on October 27, 2016 Subscribe \\nArrogance is defined as “an insulting way of thinking or behaving that comes from believing that you are better, smarter, or m...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Inside the Trump-Bush melodrama: Decades of tension and discomfort</td>\n",
       "      <td>Donald Trump spent a day in January 2014 hobnobbing with politicians at the Trump International Golf Club in West Palm Beach, Fla. The billionaire mogul touted legalizing gambling with state Rep. Steve Crisafulli, speaker of the Florida House, an...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Shutdown clash to return in force by December</td>\n",
       "      <td>Notable names include Ray Washburne (Commerce), a Dallas-based investor, is reported to be under consideration to lead the department.</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                             title  \\\n",
       "0     A whirlwind day in D.C. showcases Trump’s unorthodox views and shifting tone   \n",
       "1  In Baltimore's call for federal police probe, a new search for answers (+video)   \n",
       "2             Trump Proudly Declares: Most Of The People I’ve Insulted Deserved It   \n",
       "3               Inside the Trump-Bush melodrama: Decades of tension and discomfort   \n",
       "4                                    Shutdown clash to return in force by December   \n",
       "\n",
       "                                                                                                                                                                                                                                                        text  \\\n",
       "0  Donald Trump endorsed an unabashedly noninterventionist approach to world affairs Monday during a day-long tour of Washington, casting doubt on the need for the North Atlantic Treaty Organization and expressing skepticism about a muscular U.S. mi...   \n",
       "1  While some Justice Department investigations are adversarial, a new model of collaborative reform is surprising police in some cities, as they find themselves included as part of the solution.\\n\\nSearching for a \"framework ... [to] heal,\" Baltimo...   \n",
       "2  Trump Proudly Declares: Most Of The People I’ve Insulted Deserved It By Andrew Bradford on October 27, 2016 Subscribe \\nArrogance is defined as “an insulting way of thinking or behaving that comes from believing that you are better, smarter, or m...   \n",
       "3  Donald Trump spent a day in January 2014 hobnobbing with politicians at the Trump International Golf Club in West Palm Beach, Fla. The billionaire mogul touted legalizing gambling with state Rep. Steve Crisafulli, speaker of the Florida House, an...   \n",
       "4                                                                                                                     Notable names include Ray Washburne (Commerce), a Dallas-based investor, is reported to be under consideration to lead the department.   \n",
       "\n",
       "  label  \n",
       "0  REAL  \n",
       "1  REAL  \n",
       "2  FAKE  \n",
       "3  REAL  \n",
       "4  REAL  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = 'Data/Fake_Real_News_Data.csv'\n",
    "df=pd.read_csv(fpath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca817b2-cbac-4969-90ca-8cb50fa7e370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6335 non-null   int64 \n",
      " 1   title       6335 non-null   object\n",
      " 2   text        6335 non-null   object\n",
      " 3   label       6335 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 198.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12cfcd-d20d-468d-9bd2-520a0622bcb4",
   "metadata": {},
   "source": [
    "## **1. Clean the Data**\n",
    "- Remove any unnecessary columns and check for/ remove duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe0e6c6-8844-4f46-9d54-af58189ce59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec36765-35db-4d80-881b-eda16bfd5a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4f85b73-edb1-492d-90a0-fd6b82986b78",
   "metadata": {},
   "source": [
    "## **2. Prepare the Data** - Create 3 new columns:\n",
    "- Tokenized texts: `just split the texts, don't remove stop words or punctuation`\r",
    "- Lemmatized texts: `remove stopwords, and punctuation, and lemmatize the words`\n",
    "    - `IMPORTANT!` When you load in the SpaCy NLP object, <u>remember</u> to disable the parser and named object recognizer using the following: `spacy.load('en_core_web_sm, disable = ['parser', 'ner')`\n",
    "- Joined lemmatized data.a\n",
    "    -Join each lemmatized document into a single string.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a9bf0-824a-4a53-bbfb-af5656431f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d98987-98c2-4bf6-b22d-9a693f5879d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ccbcc7-e3cf-4b05-b40c-6b4d7b181a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e287217-bb6c-49bc-a849-9e23fe5973c1",
   "metadata": {},
   "source": [
    "## **3. Analyze class balance and document lengths:**\n",
    "- What is the class balance? How many real and fake articles are there?\n",
    "- What is the average word count for real news articles? What about fake ones?\n",
    "- `Hint`, you can map the len() function to the tolkenized text to create a new column, then find the average of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d84ac-6227-4709-be27-8a77f79fb541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a60446-83b3-4550-95ea-b3c7fcadc15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab71156-f827-4c92-bbbc-79533ce2b2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9a1faf-d365-427e-abc7-7f6bd18220be",
   "metadata": {},
   "source": [
    "## **4. Compare the word frequencies:**\n",
    "- Create and plot the frequency distribution plots for the 20 most common words in real and fake news articles `(2 total plots)`\n",
    "    - Use the lemmatized text.\n",
    "- Create word clouds for each of the article types, real and fake `(2 total word clouds)`\n",
    "    - Use the joined lemmatized text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289019c-fe54-46db-bfc7-6a33362febfd",
   "metadata": {},
   "source": [
    "### <u>Plot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e65280-3018-40cf-804a-5bc13d8453e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Fake News\n",
    "dist.plot(20, title='Fake News Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40e767-76f0-46a9-b9ec-73482a1dd9f7",
   "metadata": {},
   "source": [
    "### <u>WordCloud 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8e79a-cfa9-4f94-aa7e-102fad8d6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a WordCloud and use the generate method\n",
    "cloud = WordCloud(random_state = 123).generate(txt)\n",
    "plt.imshow(cloud);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e98483-c09a-41a4-92d9-646ab6a34e67",
   "metadata": {},
   "source": [
    "<u>Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633c6e1-5135-458e-a4c8-1b2c29be710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b8e46-f985-4916-892a-87b098d95542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ca14f-2f8c-4d3e-abc1-8824c56038ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126922d8-de89-42ef-8fb3-79adbfd887ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42486dfa-7b96-4ae2-9a48-5ed18f76d152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae8283-dd31-4f93-bafd-5984f2bc625b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d08ea-a541-439c-9315-7b84878e4575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d809784-0b97-4b16-a92d-f998906d4446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc6a4d7-ff08-4bcc-922c-2155a85af306",
   "metadata": {},
   "source": [
    "### <u>Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55aea0-1197-44c4-9e67-d3aad1d8a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Fake News\n",
    "dist.plot(20, title='Real News Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869be3aa-5259-4401-a6d1-bab255fd1296",
   "metadata": {},
   "source": [
    "### <u>WordCloud 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112768ef-2769-42b4-b10a-22b6235c6dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bac007-7aac-4822-8c9b-9468f9abc808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3e788-1768-4095-88f5-0055694b05bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577ddc7-1432-41bf-9610-615ad28c52cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edaa294-3c8b-406f-8154-28427f90f09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd56c16-6976-4c89-a9f8-2882d098102a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bb86e-7975-43c8-b3dd-355a5734ff7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a1192-c04c-4903-8393-67ece5d2aca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcd1ab-a994-4475-b3b2-25d049394304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ecf393-bf8a-4846-8589-a0d0e32fb099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a43438-9585-496f-86e1-c9e0ed382a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2de1ef-e66c-4dde-8711-e774f903b5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0e16b-5cbc-478b-ba2f-7e756910730a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
